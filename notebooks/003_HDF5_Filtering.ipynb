{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tables\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../raw/total-3L.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unbound_range(start=0):\n",
    "    current_value = start\n",
    "    while True:\n",
    "        yield current_value\n",
    "        current_value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filtering order matters for performance...\n",
    "\n",
    "def accessibility_filter(recs):\n",
    "    for rec in recs:\n",
    "        if rec['accessibility']:\n",
    "            yield rec\n",
    "\n",
    "\n",
    "def subsample_filter(recs, cut):\n",
    "    for rec in recs:\n",
    "        if random.random() < cut:\n",
    "            yield rec\n",
    "\n",
    "\n",
    "#start filter vs end filter\n",
    "def start_filter(recs, start):\n",
    "    #There would be more efficient ways of doing this...\n",
    "    for rec in recs:\n",
    "        pos = rec['pos']\n",
    "        if pos < start:\n",
    "            continue\n",
    "        else:\n",
    "            yield rec\n",
    "\n",
    "            \n",
    "def end_filter(recs, end):\n",
    "    for rec in recs:\n",
    "        pos = rec['pos']\n",
    "        if pos > end:\n",
    "            #we can do this because the input is ordered!\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            yield rec\n",
    "            \n",
    "\n",
    "def biallelic_filter(recs):\n",
    "    for rec in recs:\n",
    "        alt = rec['alt']\n",
    "        if len([x for x in alt if x != b'']) == 1:\n",
    "            yield rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_data(store):\n",
    "    genotype_array = store.get_node('/3L/calldata/genotype').iterrows()\n",
    "    called_array = store.get_node('/3L/calldata/is_called').iterrows()\n",
    "    accessibility_array = store.get_node('/3L/variants/Accessible').iterrows()\n",
    "    pos_array = store.get_node('/3L/variants/POS').iterrows()\n",
    "    alt_array = store.get_node('/3L/variants/ALT').iterrows()\n",
    "    #this will not work on Python 2 (unless you use ittertools.zip)\n",
    "    for genotype, accessibility, pos, alt, called in zip(\n",
    "        genotype_array, accessibility_array, pos_array, alt_array, called_array):\n",
    "        yield {\n",
    "            'genotype': genotype,\n",
    "            'called': called,\n",
    "            'accessibility': accessibility,\n",
    "            'pos': pos,\n",
    "            'alt': alt,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_function = partial(start_filter, start=10000000)\n",
    "end_function = partial(end_filter, end=30000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#python 3.5!\n",
    "def filter_partial_subsample(recs, subsample_function=partial(subsample_filter, cut=0.1)):\n",
    "    yield from biallelic_filter(end_function(start_function(accessibility_filter(subsample_function(recs)))))\n",
    "\n",
    "def filter_partial_subsample_slow(recs, subsample_function=partial(subsample_filter, cut=0.1)):\n",
    "    yield from end_function(start_function(accessibility_filter(subsample_function(biallelic_filter(recs)))))\n",
    "    \n",
    "def filter_partial_no_subsample(recs, subsample_function=partial(subsample_filter, cut=0.1)):\n",
    "    yield from end_function(start_function(accessibility_filter(biallelic_filter(recs))))\n",
    "    \n",
    "def filter_no_subsample(recs):\n",
    "    yield from accessibility_filter(biallelic_filter(recs))\n",
    "    \n",
    "def filter_subsample(recs, subsample_function=partial(subsample_filter, cut=0.1)):\n",
    "    yield from accessibility_filter(biallelic_filter(subsample_function(recs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store = tables.open_file(fname, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%time sum(1 for x in filter_partial_subsample(get_all_data(store)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%time print(sum(1 for x in filter_partial_subsample_slow(get_all_data(store))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 30s, sys: 2.47 s, total: 6min 32s\n",
      "Wall time: 6min 33s\n",
      "7449486\n"
     ]
    }
   ],
   "source": [
    "%time num_snps = sum(1 for x in filter_no_subsample(get_all_data(store)))\n",
    "print(num_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_hdf5(name, samples, recs, size):\n",
    "    #size will mostbly be approxiamte because it is random\n",
    "    w = tables.open_file(name, mode='w', filters=tables.Filters(complib='zlib', complevel=5))\n",
    "    genotypes = tables.EArray(w.root, 'genotypes', tables.BoolAtom(),\n",
    "                         expectedrows=size, shape=(0, len(samples), 2))\n",
    "    positions = tables.EArray(w.root, 'positions', tables.IntAtom(),\n",
    "                         expectedrows=size, shape=(0,))\n",
    "    for rec in recs:\n",
    "        old_genotypes = rec['genotype']\n",
    "        #Only works for bi-allelic and no missing data\n",
    "        min_val = old_genotypes.min()\n",
    "        positions.append([rec['pos']])\n",
    "        genotypes.append([np.array(list(map(lambda x: x == min_val, old_genotypes)))])\n",
    "    w.create_array(w.root, 'samples', samples, 'Sample ids')    \n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = store.get_node('/3L/samples').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_hdf5('subsample_010.h5', samples, filter_subsample(get_all_data(store)), int(num_snps * 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_hdf5('subsample_001.h5', samples,\n",
    "            filter_subsample(get_all_data(store),\n",
    "                             subsample_function=partial(subsample_filter, cut=0.01)),\n",
    "            int(num_snps * 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_hdf5('subsample_000c1.h5', samples,\n",
    "            filter_subsample(get_all_data(store),\n",
    "                             subsample_function=partial(subsample_filter, cut=0.001)),\n",
    "            int(num_snps * 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsample_function = partial(subsample_filter, cut=0.01)\n",
    "create_hdf5('partial_subsample_001.h5', samples,\n",
    "            filter_partial_subsample(get_all_data(store), subsample_function=partial(subsample_filter, cut=0.01)),\n",
    "            int(num_snps * 0.01 * 0.5))\n",
    "#assuming circa half SNPs (20M of 49M but centromere and telomere outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_hdf5('full.h5', samples, filter_no_subsample(get_all_data(store)), num_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#meta = pd.DataFrame.from_csv('../raw/samples.all.txt', sep='\\t')\n",
    "#pandas_sub_store = pd.HDFStore('subsample.h5')\n",
    "#pandas_sub_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
